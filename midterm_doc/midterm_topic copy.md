# 期中项目选题

> **项目形式**：小组合作（3-5人/组）
> **提交截止**：期中周

---

## 目录

1. [选题概览](#选题概览)
2. [选题一：迷宫探索与自主导航](#选题一迷宫探索与自主导航)
3. [选题二：彩色物体追踪与定位](#选题二彩色物体追踪与定位)
4. [选题三：目标搜索与巡逻任务](#选题三目标搜索与巡逻任务)
5. [选题四：多传感器融合的动态避障](#选题四多传感器融合的动态避障)
6. [项目报告要求](#项目报告要求)
7. [提交清单](#提交清单)

---

## 选题概览

|  选题  |      核心能力        |
| :--: |  :------: |
| 迷宫探索 |    路径规划     |
| 物体追踪 |    视觉感知 + 坐标变换   |
| 目标搜索 |   规划 + 感知 + 状态机  |
| 动态避障 | 多传感器融合 + 反应式控制  |

---

## 选题一：迷宫探索与自主导航

### 1. 题目描述

一个机器人被放置在一个未知迷宫的入口处，需要**自主探索**并找到通往出口的路径。机器人仅能使用激光雷达感知周围环境，不能提前获取迷宫地图。

**任务目标**：

* 从起点出发，成功到达迷宫终点
* 全程自主运行，无人工干预
* 不允许硬编码路径，需要机器自主探索
* 避免与墙壁发生碰撞

### 2. 演示效果

```
┌─────────────────────────────────┐
│  ████████████████████████████   │
│  █ 🤖→  █        █          █   │
│  █ ███  █  ████  █  ██████  █   │
│  █      █     █     █       █   │
│  ██████████   █  ████  ██████   │
│  █            █        █    🏁  │
│  ████████████████████████████   │
└─────────────────────────────────┘
       🤖 起点    🏁 终点
```

**预期展示**：

* 机器人在迷宫中自主移动
* RViz 中实时显示激光雷达扫描数据
* 机器人不与墙壁碰撞，最终到达终点

### 3. 推荐算法

寻找未知探索点可以使用Frontier算法。路径规划可以使用A*。


### 4. 加分项

| 加分项       | 描述                |
| --------- | ----------------- |
| 多种算法对比 | 实现并对比 3 种以上导航算法   |
|  最短路径优化  | 在多次运行后学习更优路径      |
|  实现多机器人迷宫探索  | 利用多机协同策略，提高迷宫探索效率     |
---

## 选题二：彩色动态物体追踪与定位

### 1. 题目描述

场景中放置了若干**彩色方块**（如绿色、红色、蓝色）。机器人需要使用相机识别**指定颜色**的目标，计算**三维坐标**，并**自主导航**至目标前方停下。

**任务目标**：


* 提供多种可以识别的颜色，允许用户指定颜色
* 正确识别指定颜色的物体，并框选出来
* 计算目标在机器人坐标系下的 3D 位置
* 驱动机器人不断跟踪着目标
* 目标物体需要动态移动

### 2. 演示效果

```
        📷 机器人视野
   ┌─────────────────────┐
   │                     │
   │    🟥      🟩       │  ← 检测到绿色方块
   │           ┌──┐      │
   │           │✓ │      │  ← 标记检测框
   │           └──┘      │
   │                     │
   └─────────────────────┘
   
   终端输出：
   [INFO] 检测到目标: 绿色方块
   [INFO] 相机坐标: (0.82, 0.15, 1.20)
   [INFO] 机器人坐标: (1.20, 0.15, 0.82)
   [INFO] 正在接近目标...
```

**预期展示**：

* 图像窗口中显示检测框和目标中心点
* 终端实时输出目标的 3D 坐标
* 机器人平稳移动至目标前方停止

### 3. 推荐算法

图像处理方面可以使用OpenCV (HSV + Contour) 颜色分割与轮廓。路径规划算法可以使用A*等算法。




### 4. 加分项

| 加分项        | 描述          |
| --------------- | ----------- |
| HSV 参数自适应    | 自动适应光照变化    |
| 多机器人动态追踪   | 框架支持多机器人对若干物体进行动态追踪 |

---

## 选题三：目标搜索与巡逻任务

### 1. 题目描述

机器人需要在一个**多区域场景**中执行巡逻任务。场景中随机放置了若干**目标物体**（绿色方块）。机器人需要：

1. **规划巡逻路径**覆盖所有区域
2. **检测并记录**发现的目标位置
3. 巡逻结束后**返回起点**
4. **发布报告**汇总所有发现的目标

### 2. 演示效果

```
   场景俯视图
┌────────────────────────────┐
│  ┌─────┐      ┌─────┐     │
│  │ A 🟩│      │  B  │     │
│  └─────┘      └─────┘     │
│         🤖                 │
│  ┌─────┐      ┌─────┐     │
│  │  C  │      │ D 🟩│     │
│  └─────┘      └─────┘     │
│                       🏠   │
└────────────────────────────┘
   🟩 目标物体  🏠 起点/终点

终端输出：
[INFO] === 巡逻任务开始 ===
[INFO] 前往区域 A...
[INFO] 发现目标! 位置: (2.3, 1.5, 0.1)
[INFO] 前往区域 B...
[INFO] 区域 B 未发现目标
[INFO] 前往区域 C...
[INFO] 前往区域 D...
[INFO] 发现目标! 位置: (4.1, -1.2, 0.1)
[INFO] 返回起点...
[INFO] === 巡逻报告 ===
[INFO] 发现目标数量: 2
[INFO] 目标位置列表:
[INFO]   1. (2.3, 1.5, 0.1)1.5, 0.1)
[INFO]   2. (4.1, -1.2, 0.1)
```

### 3. 推荐技术栈

| 模块       | 技术                  | 说明       |
| -------- | ------------------- | -------- |
| **区域导航** | 使用 Frontier进行陌生的环境探索 + `/cmd_vel`   | 依次访问各区域  |
| **目标检测** | RGB + HSV 分割        | 识别绿色方块   |
| **状态管理** | 状态机 (State Machine) | 管理巡逻逻辑   |


**状态机设计参考**：

```
         ┌──────────────┐
         │   PATROLLING │ ◄─────────┐
         └──────┬───────┘           │
                │ 到达区域           │
                ▼                   │
         ┌──────────────┐           │
         │  SEARCHING   │           │
         └──────┬───────┘           │
                │ 完成搜索           │
                ▼                   │
         ┌──────────────┐  还有区域  │
         │   LOGGING    │ ──────────┘
         └──────┬───────┘
                │ 所有区域完成
                ▼
         ┌──────────────┐
         │  RETURNING   │
         └──────┬───────┘
                │ 到达起点
                ▼
         ┌──────────────┐
         │   REPORT     │
         └──────────────┘
```

### 4. 加分项

| 加分项           |  描述                 |
| ------------- |  ------------------ |
| 区域覆盖率统计    |  计算并显示覆盖率           |
| 多机器人共同探索地图    |  部署多台机器人协同探索环境，并实现多地图融合    |

---

## 选题四：多传感器融合动态避障

### 1. 题目描述

机器人需要在一个复杂环境中从起点导航至终点。场景中包含：

* **静态障碍物**：固定位置的墙壁、柱子
* **动态障碍物**：移动的物体（如另一个移动机器人）

机器人需要**融合激光雷达和深度相机**的数据，实时检测障碍物并做出**反应式避障**决策。

### 2. 演示效果

```
  场景示意图
┌─────────────────────────────┐
│ 🏁                          │
│  ▲                          │
│  │         ████             │
│  │                          │
│  │    →🚗    ████           │  ← 动态障碍物移动中
│  │                          │
│  │              ████        │
│ 🤖                          │
└─────────────────────────────┘

   🤖 机器人  🚗 移动障碍  ████ 静态障碍

终端输出：
[INFO] 目标位置: (5.0, 4.0)
[INFO] 当前位置: (0.5, 0.3)
[WARN] 检测到动态障碍物! 距离: 1.2m 方向: 45°
[INFO] 执行避障机动...
[INFO] 障碍物已通过，恢复导航
[INFO] 已到达目标位置!
```
### 3. 推荐技术点

**模块搭建：**
- 传感器数据处理模块：使用 sensor_msgs 处理激光雷达(LaserScan)和深度相机(PointCloud2)数据
- 动态障碍物检测模块：采用帧间差分或点云对比算法识别移动物体
- 避障决策模块：实现 VFH(Vector Field Histogram)、DWA(Dynamic Window Approach)或 APF(Artificial Potential Field)等反应式避障策略
- 运动控制模块：通过 geometry_msgs/Twist 发布速度指令控制机器人移动


**传感器融合思路:**

激光雷达优势:
-  ✓ 360° 全向感知
-  ✓ 精确距离测量
-  ✗ 无法识别物体类型

深度相机优势:
-  ✓ 丰富的空间信息
-  ✓ 可结合 RGB 识别物体
-  ✗ 视野有限 (前方)

融合策略:
- → 深度相机负责前方精细检测
- → 激光雷达负责侧向和后方感知
- → 动态障碍物优先由相机检测

**程序大体逻辑（仅供参考）:**

``` python
while not reached_goal():
    # 1. 数据采集
    laser_data = get_laser_scan()      # 激光雷达数据
    depth_data = get_depth_image()     # 深度相机数据
    
    # 2. 传感器融合
    front_obstacles = detect_from_depth(depth_data)    # 前方障碍
    side_obstacles = detect_from_laser(laser_data)     # 侧后方障碍
    all_obstacles = merge(front_obstacles, side_obstacles)
    
    # 3. 动态障碍物识别
    dynamic_objects = detect_moving_objects(all_obstacles)
    
    # 4. 避障决策
    if has_collision_risk(dynamic_objects):
        velocity = compute_avoidance_velocity(all_obstacles)  # VFH/DWA/APF
    else:
        velocity = navigate_to_goal(current_pos, goal_pos)
    
    # 5. 执行控制
    publish_velocity(velocity)
```
注意：以上逻辑仅为示例框架，实际实现需要根据具体传感器、环境复杂度和性能要求进行调整优化。

### 4. 加分项

| 加分项         | 描述            |
| ----------- |  ------------- |
| 动态障碍物预测  | 预测移动障碍物轨迹     |
| 速度自适应    | 根据障碍物密度调整速度   |
| 多动态障碍物处理 | 同时处理多个移动物体    |
| 安全距离参数化  | 支持动态配置安全距离    |

---

## 提交清单

请在截止日期前提交以下材料：

|  序号 | 提交物          | 格式                | 要求            |
| :-: | ------------ | ----------------- | ------------- |
|  1  | 📦 源代码       | ROS Package (zip) | 可编译、可运行       |
|  2  | 📹 演示视频      | MP4 (≤ 100MB)     | 最多 3 分钟，附上标题，展示完整功能(handbake压制工具可以一定程度压缩视频体积) |
|  3  | 📄 项目报告      | PDF               | 按上述模板撰写       |

### 视频要求

* **时长**：最多 4 分钟
* **内容**：
  1. 录制代码编译以及执行指令的过程（可以倍速播放）(1分钟)
  2. 展示 Gazebo 仿真运行效果（30秒）
  3. 展示 RViz 可视化效果（30 分钟）
  4. 机器人运行视频（可以倍速播放）（1分种-1分30秒）
* **格式**：MP4，分辨率 ≥ 720p


### 文档要求
* 使用latex或者markdown格式完成,上交pdf版本
