# 期中项目选题

> **项目形式**：小组合作（3-5人/组）
> **提交截止**：期中周

---

## 目录

1. [选题概览](#选题概览)
2. [选题一：迷宫探索与自主导航](#选题一迷宫探索与自主导航)
3. [选题二：彩色物体追踪与定位](#选题二彩色物体追踪与定位)
4. [选题三：目标搜索与巡逻任务](#选题三目标搜索与巡逻任务)
5. [选题四：多传感器融合的动态避障](#选题四多传感器融合的动态避障)
6. [选题五（开放选题）：自主机器人任务的开放式设计与实现（需教师同意）](选题五（开放选题）：自主机器人任务的开放式设计与实现（需教师同意）)
7. [项目报告要求](#项目报告要求)
8. [提交清单](#提交清单)
9. [评分标准](#评分标准)

---

## 选题概览

|  选题  |      核心能力        |
| :--: |  :------: |
| 迷宫探索 |    路径规划     |
| 物体追踪 |   视觉感知 + 坐标变换   |
| 目标搜索 |   规划 + 感知 + 状态机  |
| 动态避障 | 多传感器融合 + 反应式控制  |

---

## 选题一：迷宫探索与自主导航

### 1. 题目描述

一个机器人被放置在一个未知迷宫的入口处，需要**自主探索**并找到通往出口的路径。机器人仅能使用激光雷达感知周围环境，不能提前获取迷宫地图。

**任务目标**：

* 从起点出发，成功到达迷宫终点
* 全程自主运行，无人工干预
* 不允许硬编码路径，需要机器自主探索
* 避免与墙壁发生碰撞

### 2. 演示效果

```
┌─────────────────────────────────┐
│  ████████████████████████████   │
│  █ 🤖→  █        █          █   │
│  █ ███  █  ████  █  ██████  █   │
│  █      █     █     █       █   │
│  ██████████   █  ████  ██████   │
│  █            █        █    🏁  │
│  ████████████████████████████   │
└─────────────────────────────────┘
       🤖 起点    🏁 终点
```

**预期展示**：

* 机器人在迷宫中自主移动
* RViz 中实时显示激光雷达扫描数据
* 机器人不与墙壁碰撞，最终到达终点

### 3. 推荐算法

寻找未知探索点可以使用Frontier算法。路径规划可以使用A*。


### 4. 加分项

| 加分项       | 描述                |
| --------- | ----------------- |
| 多种算法对比 | 实现并对比 3 种以上导航算法   |
|  最短路径优化  | 在多次运行后学习更优路径      |
|  实现多机器人迷宫探索  | 利用多机协同策略，提高迷宫探索效率     |
---

## 选题二：彩色动态物体追踪与定位

### 1. 题目描述

场景中放置了若干**彩色方块**（如绿色、红色、蓝色）。机器人需要使用相机识别**指定颜色**的目标，计算**三维坐标**，并**自主导航**至目标前方停下。

**任务目标**：


* 提供多种可以识别的颜色，允许用户指定颜色
* 正确识别指定颜色的物体，并框选出来
* 计算目标在机器人坐标系下的 3D 位置
* 驱动机器人不断跟踪着目标
* 目标物体需要动态移动

### 2. 演示效果

```
        📷 机器人视野
   ┌─────────────────────┐
   │                     │
   │    🟥      🟩       │  ← 检测到绿色方块
   │           ┌──┐      │
   │           │✓ │      │  ← 标记检测框
   │           └──┘      │
   │                     │
   └─────────────────────┘
   
   终端输出：
   [INFO] 检测到目标: 绿色方块
   [INFO] 相机坐标: (0.82, 0.15, 1.20)
   [INFO] 机器人坐标: (1.20, 0.15, 0.82)
   [INFO] 正在接近目标...
```

**预期展示**：

* 图像窗口中显示检测框和目标中心点
* 终端实时输出目标的 3D 坐标
* 机器人平稳移动至目标前方停止

### 3. 推荐算法

图像处理方面可以使用OpenCV (HSV + Contour) 颜色分割与轮廓。路径规划算法可以使用A*等算法。




### 4. 加分项

| 加分项        | 描述          |
| --------------- | ----------- |
| HSV 参数自适应    | 自动适应光照变化    |
| 多机器人动态追踪   | 框架支持多机器人对若干物体进行动态追踪 |

---

## 选题三：目标搜索与巡逻任务

### 1. 题目描述

机器人需要在一个**多区域场景**中执行巡逻任务。场景中随机放置了若干**目标物体**（绿色方块）。机器人需要：

1. **规划巡逻路径**覆盖所有区域
2. **检测并记录**发现的目标位置
3. 巡逻结束后**返回起点**
4. **发布报告**汇总所有发现的目标

### 2. 演示效果

```
   场景俯视图
┌────────────────────────────┐
│  ┌─────┐      ┌─────┐     │
│  │ A 🟩│      │  B  │     │
│  └─────┘      └─────┘     │
│         🤖                 │
│  ┌─────┐      ┌─────┐     │
│  │  C  │      │ D 🟩│     │
│  └─────┘      └─────┘     │
│                       🏠   │
└────────────────────────────┘
   🟩 目标物体  🏠 起点/终点

终端输出：
[INFO] === 巡逻任务开始 ===
[INFO] 前往区域 A...
[INFO] 发现目标! 位置: (2.3, 1.5, 0.1)
[INFO] 前往区域 B...
[INFO] 区域 B 未发现目标
[INFO] 前往区域 C...
[INFO] 前往区域 D...
[INFO] 发现目标! 位置: (4.1, -1.2, 0.1)
[INFO] 返回起点...
[INFO] === 巡逻报告 ===
[INFO] 发现目标数量: 2
[INFO] 目标位置列表:
[INFO]   1. (2.3, 1.5, 0.1)1.5, 0.1)
[INFO]   2. (4.1, -1.2, 0.1)
```

### 3. 推荐算法


使用 Frontier进行陌生的环境探索。目标检测方面使用RGB + HSV 分割来识别特定颜色的方块。使用状态机来管理巡逻逻辑。

**状态机设计参考**：

```
         ┌──────────────┐
         │     巡逻     │ ◄─────────┐
         └──────┬───────┘           │
                │ 到达区域           │
                ▼                   │
         ┌──────────────┐           │
         │     搜索     │
         └──────┬───────┘           │
                │ 完成搜索           │
                ▼                   │
         ┌──────────────┐  还有区域  │
         │     记录     │ ──────────┘
         └──────┬───────┘
                │ 所有区域完成
                ▼
         ┌──────────────┐
         │     返回     │
         └──────┬───────┘
                │ 到达起点
                ▼
         ┌──────────────┐
         │     完成     │
         └──────────────┘
```

### 4. 加分项

| 加分项           |  描述                 |
| ------------- |  ------------------ |
| 区域覆盖率统计    |  计算并显示覆盖率           |
| 多机器人共同探索地图    |  部署多台机器人协同探索环境，并实现多地图融合    |

---

## 选题四：多传感器融合动态避障

### 1. 题目描述

机器人需要在一个复杂环境中从起点导航至终点。场景中包含：

* **静态障碍物**：固定位置的墙壁、柱子
* **动态障碍物**：移动的物体（如另一个移动机器人）

机器人需要**融合激光雷达和深度相机**的数据，实时检测障碍物并做出**反应式避障**决策。

### 2. 演示效果

```
  场景示意图
┌─────────────────────────────┐
│ 🏁                          │
│  ▲                          │
│  │         ████             │
│  │                          │
│  │    →🚗    ████           │  ← 动态障碍物移动中
│  │                          │
│  │              ████        │
│ 🤖                          │
└─────────────────────────────┘

   🤖 机器人  🚗 移动障碍  ████ 静态障碍

终端输出：
[INFO] 目标位置: (5.0, 4.0)
[INFO] 当前位置: (0.5, 0.3)
[WARN] 检测到动态障碍物! 距离: 1.2m 方向: 45°
[INFO] 执行避障机动...
[INFO] 障碍物已通过，恢复导航
[INFO] 已到达目标位置!
```
### 3. 推荐算法

全局路径规划通常采用 
𝐴∗或 Dijkstra 算法，在已知静态地图中基于代价函数搜索出从起点到终点的最优路径。

局部避障决策与运动控制核心依赖 DWA (动态窗口法) 或 APF (人工势场法)，通过在速度空间 𝑣,𝜔 中采样并计算轨迹评价函数，实时生成能够规避动态障碍物的平滑速度指令。

针对动态物体识别与传感器融合，利用 卡尔曼滤波 (Kalman Filter) 进行状态估计与轨迹预测，结合 ICP (迭代最近点) 算法处理点云数据，能有效融合激光雷达与深度相机信息以精确锁定移动目标。

### 4. 加分项

| 加分项         | 描述            |
| ----------- |  ------------- |
| 动态障碍物预测  | 预测移动障碍物轨迹     |
| 速度自适应    | 根据障碍物密度调整速度   |
| 多动态障碍物处理 | 同时处理多个移动物体    |
| 安全距离参数化  | 支持动态配置安全距离    |

---



## 选题五（开放选题）：自主机器人任务的开放式设计与实现（需教师同意）

> ⚠️ **说明**：本选题为**开放式自拟项目**。
>  学生需自行设计具体任务与应用场景，并在期中前提交项目方案，经任课教师同意后方可作为期中项目。

------

### 1. 题目描述

本选题不预先规定具体任务形式。
 学生小组可根据兴趣与能力，自行设计一个**完整的机器人应用场景**，如但不限于：

- 自主探索与导航
- 目标检测与跟踪
- 巡逻、搜索
- 动态避障与决策
- 多任务或多阶段执行流程

项目复杂度与应用背景均不作硬性规定，但因结合课程内容进行合理设计。

------

### 2. 技术方向参考

项目可**选择性地**涉及以下内容（不要求全部覆盖）：

- ROS 节点通信与基本系统搭建
- 相机视觉或深度 / 点云感知
- 坐标系与位姿表示
- 路径规划、导航或避障
- 简单任务逻辑或状态切换

是否采用、采用多少，由小组根据项目设计自行决定。

------

### 3. 项目基本要求

- 项目应具备**明确的任务目标和演示流程**
- 机器人行为应体现一定程度的自主性
- 项目规模应与期中项目工作量相匹配

------

### 4. 项目方案确认

为保证项目难度和方向合理，小组需在实现前向任课教师提交**简要项目说明**（可为文字或示意图），经同意后方可开展。

## 提交清单

请在截止日期前提交以下材料：

|  序号 | 提交物          | 格式                | 要求            |
| :-: | ------------ | ----------------- | ------------- |
|  1  | 📦 源代码       | ROS Package (zip) | 可编译、可运行       |
|  2  | 📹 演示视频      | MP4 (≤ 100MB)     | 最多 3 分钟，附上标题，展示完整功能(handbake压制工具可以一定程度压缩视频体积) |
|  3  | 📄 项目报告      | PDF               | 按模板撰写       |

### 视频要求

* **时长**：最多 4 分钟
* **内容**：
  1. 录制代码编译以及执行指令的过程（可以倍速播放）(1分钟)
  2. 展示 Gazebo 仿真运行效果（30秒）
  3. 展示 RViz 可视化效果（30 分钟）
  4. 机器人运行视频（可以倍速播放）（1分种-1分30秒）
* **格式**：MP4，分辨率 ≥ 720p


### 文档要求
* 使用latex或者markdown格式完成,上交pdf版本

## 评分标准

期中项目成绩将综合考虑**项目选题难度、任务完成情况、技术实现质量、项目报告内容以及演示效果**进行评定。

评分重点包括但不限于：

- **项目选题本身的难度与挑战性**，在合理范围内，选题越复杂、技术要求越高，评分越高
- **项目是否完整实现既定任务目标**，系统能否稳定、自主运行
- **机器人实际演示效果**（Gazebo / RViz / 实际或仿真运行），运行越稳定、效果越清晰，评分越高
- **项目技术难度与工作量**，在完成基础要求的前提下，任务设计更复杂、实现难度更高的项目将获得更高评价
- **项目报告质量**，是否清楚说明系统设计思路、算法流程与实验结果

需要特别说明的是：**实际完成度是评分的重要前提**。建议各小组**优先在实际机器人系统中可靠地完成一个相对简单、明确的基础任务**，在此基础上**逐步扩展任务难度和系统复杂度**。**仅有高难度设计但缺乏可行实现的项目，其评分将受到明显限制。**

本项目为**小组合作项目**，但**组内成员成绩不完全相同**。 最终个人成绩将根据**小组项目整体表现**，并结合**每位成员在项目中的实际贡献度与分工情况**进行调整。 贡献度高、承担核心工作的成员将获得更高成绩，贡献较少或参与不足的成员成绩将相应降低。