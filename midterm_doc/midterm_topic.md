# 期中项目选题

> **项目形式**：小组合作（3-5人/组）
> **提交截止**：期中周

---

## 目录

1. [选题概览](#选题概览)
2. [选题一：迷宫探索与自主导航](#选题一迷宫探索与自主导航)
3. [选题二：彩色物体追踪与定位](#选题二彩色物体追踪与定位)
4. [选题三：目标搜索与巡逻任务](#选题三目标搜索与巡逻任务)
5. [选题四：多传感器融合的动态避障](#选题四多传感器融合的动态避障)
6. [项目报告要求](#项目报告要求)
7. [提交清单](#提交清单)

---

## 选题概览

|  选题  |      核心能力        |
| :--: |  :------: |
| 迷宫探索 |    路径规划     |
| 物体追踪 |    视觉感知 + 坐标变换   |
| 目标搜索 |   规划 + 感知 + 状态机  |
| 动态避障 | 多传感器融合 + 反应式控制  |

---

## 选题一：迷宫探索与自主导航

### 1. 题目描述

一个机器人被放置在一个未知迷宫的入口处，需要**自主探索**并找到通往出口的路径。机器人仅能使用激光雷达感知周围环境，不能提前获取迷宫地图。

**任务目标**：

* 从起点出发，成功到达迷宫终点
* 全程自主运行，无人工干预
* 不允许硬编码路径，需要机器自主探索
* 避免与墙壁发生碰撞

### 2. 演示效果

```
┌─────────────────────────────────┐
│  ████████████████████████████   │
│  █ 🤖→  █        █          █   │
│  █ ███  █  ████  █  ██████  █   │
│  █      █     █     █       █   │
│  ██████████   █  ████  ██████   │
│  █            █        █    🏁  │
│  ████████████████████████████   │
└─────────────────────────────────┘
       🤖 起点    🏁 终点
```

**预期展示**：

* 机器人在迷宫中自主移动
* RViz 中实时显示激光雷达扫描数据
* 机器人不与墙壁碰撞，最终到达终点

### 3. 推荐算法

寻找未知探索点可以使用Frontier算法。路径规划可以使用A*。


### 4. 加分项

| 加分项       | 描述                |
| --------- | ----------------- |
| 多种算法对比 | 实现并对比 3 种以上导航算法   |
|  最短路径优化  | 在多次运行后学习更优路径      |
|  实现多机器人迷宫探索  | 利用多机协同策略，提高迷宫探索效率     |
---

## 选题二：彩色动态物体追踪与定位

### 1. 题目描述

场景中放置了若干**彩色方块**（如绿色、红色、蓝色）。机器人需要使用相机识别**指定颜色**的目标，计算**三维坐标**，并**自主导航**至目标前方停下。

**任务目标**：


* 提供多种可以识别的颜色，允许用户指定颜色
* 正确识别指定颜色的物体，并框选出来
* 计算目标在机器人坐标系下的 3D 位置
* 驱动机器人不断跟踪着目标
* 目标物体需要动态移动

### 2. 演示效果

```
        📷 机器人视野
   ┌─────────────────────┐
   │                     │
   │    🟥      🟩       │  ← 检测到绿色方块
   │           ┌──┐      │
   │           │✓ │      │  ← 标记检测框
   │           └──┘      │
   │                     │
   └─────────────────────┘
   
   终端输出：
   [INFO] 检测到目标: 绿色方块
   [INFO] 相机坐标: (0.82, 0.15, 1.20)
   [INFO] 机器人坐标: (1.20, 0.15, 0.82)
   [INFO] 正在接近目标...
```

**预期展示**：

* 图像窗口中显示检测框和目标中心点
* 终端实时输出目标的 3D 坐标
* 机器人平稳移动至目标前方停止

### 3. 推荐算法

图像处理方面可以使用OpenCV (HSV + Contour) 颜色分割与轮廓。路径规划算法可以使用A*等算法。




### 4. 加分项

| 加分项        | 描述          |
| --------------- | ----------- |
| HSV 参数自适应    | 自动适应光照变化    |
| 多机器人动态追踪   | 框架支持多机器人对若干物体进行动态追踪 |

---

## 选题三：目标搜索与巡逻任务

### 1. 题目描述

机器人需要在一个**多区域场景**中执行巡逻任务。场景中随机放置了若干**目标物体**（绿色方块）。机器人需要：

1. **规划巡逻路径**覆盖所有区域
2. **检测并记录**发现的目标位置
3. 巡逻结束后**返回起点**
4. **发布报告**汇总所有发现的目标

### 2. 演示效果

```
   场景俯视图
┌────────────────────────────┐
│  ┌─────┐      ┌─────┐     │
│  │ A 🟩│      │  B  │     │
│  └─────┘      └─────┘     │
│         🤖                 │
│  ┌─────┐      ┌─────┐     │
│  │  C  │      │ D 🟩│     │
│  └─────┘      └─────┘     │
│                       🏠   │
└────────────────────────────┘
   🟩 目标物体  🏠 起点/终点

终端输出：
[INFO] === 巡逻任务开始 ===
[INFO] 前往区域 A...
[INFO] 发现目标! 位置: (2.3, 1.5, 0.1)
[INFO] 前往区域 B...
[INFO] 区域 B 未发现目标
[INFO] 前往区域 C...
[INFO] 前往区域 D...
[INFO] 发现目标! 位置: (4.1, -1.2, 0.1)
[INFO] 返回起点...
[INFO] === 巡逻报告 ===
[INFO] 发现目标数量: 2
[INFO] 目标位置列表:
[INFO]   1. (2.3, 1.5, 0.1)1.5, 0.1)
[INFO]   2. (4.1, -1.2, 0.1)
```

### 3. 推荐算法


使用 Frontier进行陌生的环境探索。目标检测方面使用RGB + HSV 分割来识别特定颜色的方块。使用状态机来管理巡逻逻辑。

**状态机设计参考**：

```
         ┌──────────────┐
         │     巡逻     │ ◄─────────┐
         └──────┬───────┘           │
                │ 到达区域           │
                ▼                   │
         ┌──────────────┐           │
         │     搜索     │
         └──────┬───────┘           │
                │ 完成搜索           │
                ▼                   │
         ┌──────────────┐  还有区域  │
         │     记录     │ ──────────┘
         └──────┬───────┘
                │ 所有区域完成
                ▼
         ┌──────────────┐
         │     返回     │
         └──────┬───────┘
                │ 到达起点
                ▼
         ┌──────────────┐
         │     完成     │
         └──────────────┘
```

### 4. 加分项

| 加分项           |  描述                 |
| ------------- |  ------------------ |
| 区域覆盖率统计    |  计算并显示覆盖率           |
| 多机器人共同探索地图    |  部署多台机器人协同探索环境，并实现多地图融合    |

---

## 选题四：多传感器融合动态避障

### 1. 题目描述

机器人需要在一个复杂环境中从起点导航至终点。场景中包含：

* **静态障碍物**：固定位置的墙壁、柱子
* **动态障碍物**：移动的物体（如另一个移动机器人）

机器人需要**融合激光雷达和深度相机**的数据，实时检测障碍物并做出**反应式避障**决策。

### 2. 演示效果

```
  场景示意图
┌─────────────────────────────┐
│ 🏁                          │
│  ▲                          │
│  │         ████             │
│  │                          │
│  │    →🚗    ████           │  ← 动态障碍物移动中
│  │                          │
│  │              ████        │
│ 🤖                          │
└─────────────────────────────┘

   🤖 机器人  🚗 移动障碍  ████ 静态障碍

终端输出：
[INFO] 目标位置: (5.0, 4.0)
[INFO] 当前位置: (0.5, 0.3)
[WARN] 检测到动态障碍物! 距离: 1.2m 方向: 45°
[INFO] 执行避障机动...
[INFO] 障碍物已通过，恢复导航
[INFO] 已到达目标位置!
```
### 3. 推荐算法

全局路径规划通常采用 
𝐴∗或 Dijkstra 算法，在已知静态地图中基于代价函数搜索出从起点到终点的最优路径。

局部避障决策与运动控制核心依赖 DWA (动态窗口法) 或 APF (人工势场法)，通过在速度空间 𝑣,𝜔 中采样并计算轨迹评价函数，实时生成能够规避动态障碍物的平滑速度指令。

针对动态物体识别与传感器融合，利用 卡尔曼滤波 (Kalman Filter) 进行状态估计与轨迹预测，结合 ICP (迭代最近点) 算法处理点云数据，能有效融合激光雷达与深度相机信息以精确锁定移动目标。

### 4. 加分项

| 加分项         | 描述            |
| ----------- |  ------------- |
| 动态障碍物预测  | 预测移动障碍物轨迹     |
| 速度自适应    | 根据障碍物密度调整速度   |
| 多动态障碍物处理 | 同时处理多个移动物体    |
| 安全距离参数化  | 支持动态配置安全距离    |

---

## 提交清单

请在截止日期前提交以下材料：

|  序号 | 提交物          | 格式                | 要求            |
| :-: | ------------ | ----------------- | ------------- |
|  1  | 📦 源代码       | ROS Package (zip) | 可编译、可运行       |
|  2  | 📹 演示视频      | MP4 (≤ 100MB)     | 最多 3 分钟，附上标题，展示完整功能(handbake压制工具可以一定程度压缩视频体积) |
|  3  | 📄 项目报告      | PDF               | 按模板撰写       |

### 视频要求

* **时长**：最多 4 分钟
* **内容**：
  1. 录制代码编译以及执行指令的过程（可以倍速播放）(1分钟)
  2. 展示 Gazebo 仿真运行效果（30秒）
  3. 展示 RViz 可视化效果（30 分钟）
  4. 机器人运行视频（可以倍速播放）（1分种-1分30秒）
* **格式**：MP4，分辨率 ≥ 720p


### 文档要求
* 使用latex或者markdown格式完成,上交pdf版本
